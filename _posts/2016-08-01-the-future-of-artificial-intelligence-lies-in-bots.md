---
layout: post
title: "The future of artificial intelligence lies in bots"
date: 2016-08-01
hero: /images/tree.jpg
---

A real life assistant is expected to be a jack-of-all-trades. Whether finding a room for my meeting (and knowing how important the other meetings are to determine who else I can kick out), or booking me a cab back from my event (and knowing that I’d rather leave early to avoid the rush than see the whole thing but have to hang around afterwards); genuine intelligence is absolutely required, as is flexibility and persistence.

Which is why digital assistants have been unmitigated failures. Siri, Google Now, Cortana and Alexa all offer fantastic features. Predictive search makes me feel like I’m living in the future. But it’s hard not to feel like we’ve been sold an over-reaching dream: a digital assistant that can look after my life’s admin for me.

> Digital assistants have been unmitigated failures.

Artificial intelligences are improving all the time, and experienced tech entrepreneurs (including Bill Gates and Elon Musk) are afraid the robots will take over and rule us pitiful humans with an iron fist. So far it’s clear we have nothing to worry about. Despite hype around “machine learning” and “neural networks”, the best AI can offer right now is limited success at completing tasks. DeepMind can win at Go, a game that requires humans to understand strategy and nuance, but DeepMind doesn’t know what strategy or nuance are. DeepMind analysed thousands (or millions) of games, understood what types of moves lead to wins, and extrapolated to be able to win. It wasn’t learning by rote, but nor was it exactly self-aware. Instead of proving that computers are capable of intuition, we proved that the game didn’t need intuition as much as we thought it did.

In most people’s lives Google Now is the closest we get to interacting with AI. It uses pattern recognition to understand what features of a news story are in common between things I seem to be interested in. It can tell that I am more likely to read stories that are about politics or technology than about celebrities or personal finance. It knows that I’m more likely to read it if it’s on the guardian than on the bbc. It knows that I read a lot about football, but only premier league. That kind of pattern recognition makes it extremely effective at suggesting new stories for me to read. By then layering on the overall popularity of those stories it can make recommendations not disimilar to a human’s curation.

> Google Now knows that I support Aston Villa, but not how sad I am about that.

To any eye, though, it’s obviously not human curation. It still doesn’t recognise what makes an article interesting, well written, shocking or thought provoking. It can recognise when the article resonates with other people and contains topics I read, but it couldn’t tell me why.

There’s a question about whether that matters. Is it important to mimic how humans make decisions, or is it okay to just brute force the problem if the output is similar? In 1953 Milton Friedman made an argument about economic or scientific models: do we care whether the model accurately reflects reality, so long as it accurately predicts the output?

He used the example of a billiards player. To try to write a mathematical model of a billiards player that mimicked the real world would need understanding of a lot of variables. To model movement we’d need to understand the lengths of his limbs, the contractile strength and control of his muscles, his joint flexibility. To model accuracy we’d need to understand his eyesight, his stance and the qualities of the cue. To model decision making we’d need to know how his brain converts the visual signals into an image of the table, how he judges the force to apply to the cue, how his nerves pass the signals to his muscles. Let’s build this model, and call it model A.

The alternative is model B. We know most professional billiards players are incredible, so let’s assume he’s a perfect machine. If we just use Newton’s laws to calculate the perfect shot, we’ve got a mathematical model.

If I build model B and ask you to build model A you’ll fail. The very best systems in the world couldn’t make model A as accurate a predictor of our billiards player as model B. But model B isn’t a representation of the real world. It ignores the player entirely and assumes he’ll behave just like the maths. It works, but at a cost. That cost is how useful the model is to future generations. If we focus on output over method we run the risk of being unable to ever improve our model. The physics of the billiards table don’t change, so how do we refine it? If we understand how the billiards player works we can factor in that he might shake if he’s low on potassium, or that he’s several years older and his eyesight has degraded. Our model could be changed to account for an unexpected sneeze.

What this means is that it matters how we reach our output. We can’t try to mimic human curation and activity via pattern recognition and expect it to ever be as good as the real thing. This is why our digital assistants are so underwhelming: they’re great at some tasks, but by setting expectations that they can behave like a human we’ll always be disappointed.

> It matters how we reach our output.

The companies who have made digital assistants have made them to be jacks-of-all-trades, and this is a dead end for technology until we can actually model intelligence, rather than mimic it. Some companies are now helping lead a charge away from the digital assistant model, towards bots.

A “bot” is a charged name. It implies dumb responsiveness, and they’re so accessible they’ve been used poorly and publicly in the past. This very accessibility might prove to be their greatest strength thanks to a single recent development: natural language processing.

A bot is simple: it lives in a chat-based environment (it’s input/output with the user is restricted to text/voice) and sends pre-programmed responses to the right input. In the past the limitation has been around that “right” input. It’s very hard for a machine to interpret what a person wants as well as another person does. If I want a bot to book me a cab, I need to frame my request in exactly the format it needs: “Book me a cab from [departure] to [destination]” with no variance in sentence structure, grammar or even word choice.

Now that natural language processing is more usable we’re starting to see the ease of interacting with bots improve. A bot can be programmed with limited inputs (e.g. Departure, Destination, Pickup_Time), and the language engine can translate from human to machine. I could ask the system “Could you get me a cab home in twenty minutes?” and it could pick that sentence apart, understand that “home” is the destination, “twenty minutes” turns into a fixed pickup time, and that the departure point is implicit in the sentence, and should be my current location. By offloading the understanding and making it separate to the task being performed, we can start to move away from jacks-of-all-trades.

In this environment we can imagine an ecosystem of task-specific bots, each can be good at their own job. A bot could take my lunch order and arrange delivery, a bot could provide me with directions to my next meeting, a bot could turn my heating on when I leave work at the end of the day. Each of these is achievable now, but natural language processing means I don’t need to memorise how to use each one.

The end result is exactly like apps. That’s a good thing, because the success of having apps to perform actions shows the user desire for these outputs. The limitation on apps is that we simply don’t want too many. Most apps are installed and never opened, or never used after they’re installed. Each is a separate ecosystem of its own, with a unique user interface, a unique set of commands to learn, and a unique set of challenges.

Bots avoid those problems by working within an ecosystem you already use, and with an interface you already know. Bots live within a chat environment. SMS, Hangouts, Whatsapp, Snapchat, Telegram, Line, WeChat, Twitter, Messenger, Slack, Yammer… it’s a long list but they all share the same input: text (or voice converted to text). Since a bot only needs that text input it can receive it from any of these systems. As a user I can stay in the same environment I already use and know, and achieve tasks without needing to remember the vagaries of each system: the natural language tools interpret my wishes into the inputs the bot requires. If I missed something, it can ask me in a simple and straightforward way.

Bots can be created simply. The difficult bits (the language processors, the interaction with back-end web APIs to get things done) already exist, and can be easily plugged in. All a bot creator needs to do is specify the right inputs, the likely ways they will be received, and what to do as a result.

They can be so easy to use that our jack-of-all-trades assistants can even interact with them on our behalf. Rather than expect Siri to build links to every service, it could use iMessage to interact with the brand’s bot. If Siri were to hold my personal information (home address, work address, current location, email, payment methods, etc) I wouldn’t need an account with that brand to complete the action. In fact I wouldn’t necessarily need to know which brand Siri has chosen to interact with. Siri doesn’t need to understand how to parse my request, it just needs to help fill in the information blanks for me.

The user interface of “apps” isn’t dying, but app growth has stagnated and app usage has consolidated to a very small number. Breaking into the market for user attention on their smartphones (or even on the web) is more difficult and will become increasingly more so as each walled garden takes more and more attention into itself (e.g. Facebook Instant Articles, Apple News). As a brand there is an alternative. If your input and user-facing output can be handled as text, consider whether a bot might be a way to reduce the barrier to engagement, to make it easier for users (and their other tech) to interact with you, and get closer to a real digital assistant without using the dead end of artificial intelligence.
